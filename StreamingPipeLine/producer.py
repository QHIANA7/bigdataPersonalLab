import json
import aiohttp
import asyncio
import logging
from datetime import datetime
from confluent_kafka import Producer

# ì„¤ì •
BROKER = "s1:9092,s2:9092,s3:9092"
TOPIC = "topic1"
API_BASE_URL = "http://finfra.iptime.org:9872"
DEVICE_IDS = list(range(1, 6))  # 1~5ë²ˆ ì¥ë¹„
FETCH_INTERVAL = 5
MAX_CONCURRENCY = 2  # ë™ì‹œì— ìš”ì²­í•  ìµœëŒ€ ì¥ë¹„ ìˆ˜

# ë¡œê¹…
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AsyncFMSProducer:
    def __init__(self):
        self.producer = Producer({'bootstrap.servers': BROKER})

    async def fetch_and_send(self, session, device_id):
        url = f"{API_BASE_URL}/{device_id}/"
        async with self.semaphore:
            try:
                async with session.get(url, timeout=5) as response:
                    if response.status == 200:
                        data = await response.json()
                        data["collected_at"] = datetime.now().isoformat()
                        self.send_to_kafka(data)
                        logger.info(f"âœ… Device {device_id}: ì „ì†¡ ì™„ë£Œ")
                    else:
                        logger.warning(f"âš ï¸ Device {device_id}: HTTP {response.status}")
            except Exception as e:
                logger.error(f"âŒ Device {device_id}: ìš”ì²­ ì‹¤íŒ¨ - {e}")

    def send_to_kafka(self, data):
        try:
            self.producer.produce(
                topic=TOPIC,
                key=str(data.get("DeviceId")),
                value=json.dumps(data),
                callback=self.delivery_callback
            )
            self.producer.poll(0)
        except Exception as e:
            logger.error(f"Kafka ì „ì†¡ ì‹¤íŒ¨: {e}")

    def delivery_callback(self, err, msg):
        if err:
            logger.error(f"âŒ ë©”ì‹œì§€ ì‹¤íŒ¨: {err}")
        else:
            logger.debug(f"ğŸ“¨ ë©”ì‹œì§€ ì „ì†¡ë¨ {msg.topic()} [{msg.partition()}] @ {msg.offset()}")

    async def run_loop(self):
        logger.info("ğŸ“¡ Async FMS Producer ì‹œì‘")

        
        self.semaphore = asyncio.Semaphore(MAX_CONCURRENCY)
        
        while True:
            start = datetime.now()
            async with aiohttp.ClientSession() as session:
                tasks = [self.fetch_and_send(session, device_id) for device_id in DEVICE_IDS]
                await asyncio.gather(*tasks)

            self.producer.flush()

            elapsed = (datetime.now() - start).total_seconds()
            sleep_time = max(0, FETCH_INTERVAL - elapsed)
            logger.info(f"ğŸ•’ ë‹¤ìŒ ìˆ˜ì§‘ê¹Œì§€ {sleep_time:.1f}ì´ˆ ëŒ€ê¸°...")
            await asyncio.sleep(sleep_time)

def main():
    producer = AsyncFMSProducer()
    asyncio.run(producer.run_loop())

if __name__ == "__main__":
    main()